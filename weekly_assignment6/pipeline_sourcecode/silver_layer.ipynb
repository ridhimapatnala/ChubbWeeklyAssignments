{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f83ffd99-5b80-476a-9cd9-55c1d2c0eb10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SILVER LAYER (Clean + Valid Records)\n",
    "- Data Cleaning\n",
    "    - Duplicates removed: dropDuplicates(transaction_id)\n",
    "    - Null handling: expectations + defaults\n",
    "    - Timestamp standardization: explicit to_timestamp + UTC\n",
    "    - Schema enforced: explicit casts\n",
    "\n",
    "- Incremental Processing\n",
    "    - read_stream from Bronze\n",
    "    - Watermark on UTC timestamp\n",
    "    - Idempotent via checkpoints + deduplication\n",
    "\n",
    "- Data Calibration\n",
    "    - total_amount recalculated every time\n",
    "    - Incorrect source totals overridden\n",
    "    - Currency standardized\n",
    "\n",
    "- Data Quality Rules\n",
    "    - quantity > 0\n",
    "    - unit_price > 0\n",
    "    - Invalid rows removed\n",
    "\n",
    "- Quarantine Handling\n",
    "    - Separate Delta table\n",
    "    - Rejection reason logged\n",
    "    - Original data preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8675102-03d7-4298-8797-3c40786475ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fd33363-11d4-4cf3-9733-61dd6de4e1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_sales_transactions\",\n",
    "    comment=\"Cleaned, calibrated, and validated sales transactions\",\n",
    "    table_properties={\n",
    "        \"quality\": \"silver\",\n",
    "                      }\n",
    ")\n",
    "\n",
    "# data quality rules\n",
    "@dlt.expect(\"not_null_transaction_id\", \"transaction_id IS NOT NULL\")\n",
    "@dlt.expect(\"valid_quantity\", \"quantity > 0\")\n",
    "@dlt.expect(\"valid_unit_price\", \"unit_price > 0\")\n",
    "\n",
    "def silver_sales_transactions():\n",
    "\n",
    "    sales = dlt.read_stream(\"bronze_sales_transactions\")\n",
    "    products = dlt.read(\"bronze_product_master\")\n",
    "    stores = dlt.read(\"bronze_store_region\")\n",
    "\n",
    "    cleaned = (\n",
    "        sales\n",
    "        # Timestamp standardization\n",
    "        .withColumn(\n",
    "            \"transaction_timestamp_parsed\",\n",
    "            F.to_timestamp(\"transaction_timestamp\", \"yyyy-MM-dd HH:mm:ss\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"transaction_timestamp_utc\",\n",
    "            F.to_utc_timestamp(\"transaction_timestamp_parsed\", \"UTC\")\n",
    "        )\n",
    "\n",
    "        # Type enforcement\n",
    "        .withColumn(\"quantity\", F.col(\"quantity\").cast(IntegerType()))\n",
    "        .withColumn(\"unit_price\", F.col(\"unit_price\").cast(DecimalType(10, 2)))\n",
    "        .withColumn(\"discount\", F.coalesce(F.col(\"discount\"), F.lit(0)).cast(DecimalType(10, 2)))\n",
    "\n",
    "        # Data calibration \n",
    "        .withColumn(\n",
    "            \"calculated_total_amount\",\n",
    "            (F.col(\"quantity\") * F.col(\"unit_price\") - F.col(\"discount\"))\n",
    "            .cast(DecimalType(12, 2))\n",
    "        )\n",
    "        .withColumn(\"total_amount\", F.col(\"calculated_total_amount\"))\n",
    "\n",
    "        # Currency normalization\n",
    "        .withColumn(\"currency\", F.upper(F.coalesce(\"currency\", F.lit(\"USD\"))))\n",
    "\n",
    "        # Incremental processing\n",
    "        .withWatermark(\"transaction_timestamp_utc\", \"1 day\")\n",
    "    )\n",
    "\n",
    "    # Foreign key validation\n",
    "    validated = (\n",
    "        cleaned\n",
    "        .join(products.select(\"product_id\"), \"product_id\", \"left_semi\")\n",
    "        .join(stores.select(\"store_id\"), \"store_id\", \"left_semi\")\n",
    "        .dropDuplicates([\"transaction_id\"])\n",
    "    )\n",
    "\n",
    "    return validated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b3f421b-2abb-4c84-b692-93f01af4417c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SILVER SALES QUARANTINE TABLE (INVALID RECORDS)\n",
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_sales_quarantine\",\n",
    "    comment=\"Invalid sales records quarantined during validation\",\n",
    "    table_properties={\"quality\": \"quarantine\"}\n",
    ")\n",
    "def silver_sales_quarantine():\n",
    "\n",
    "    sales = dlt.read_stream(\"bronze_sales_transactions\")\n",
    "\n",
    "    quarantined = (\n",
    "        sales\n",
    "        .withColumn(\n",
    "            \"rejection_reason\",\n",
    "            F.when(F.col(\"transaction_id\").isNull(), \"NULL_TRANSACTION_ID\")\n",
    "             .when(F.col(\"quantity\") <= 0, \"INVALID_QUANTITY\")\n",
    "             .when(F.col(\"unit_price\") <= 0, \"INVALID_UNIT_PRICE\")\n",
    "             .otherwise(\"UNKNOWN_REASON\")\n",
    "        )\n",
    "        .filter(\n",
    "            (F.col(\"transaction_id\").isNull()) |\n",
    "            (F.col(\"quantity\") <= 0) |\n",
    "            (F.col(\"unit_price\") <= 0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return quarantined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "debcd724-d6c8-448d-a12a-e5289e9e2bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SILVER PRODUCT MASTER\n",
    "@dlt.table(\n",
    "    name=\"silver_product_master\",\n",
    "    comment=\"Cleaned and standardized product master data\",\n",
    "    table_properties={\"quality\": \"silver\"}\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_product_id\", \"product_id IS NOT NULL\")\n",
    "def silver_product_master():\n",
    "\n",
    "    df = dlt.read_stream(\"bronze_product_master\")\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"product_name\", F.trim(F.upper(\"product_name\")))\n",
    "        .withColumn(\"category\", F.trim(F.upper(\"category\")))\n",
    "        .withColumn(\"brand\", F.trim(F.upper(\"brand\")))\n",
    "        .withColumn(\"standard_price\", F.col(\"standard_price\").cast(DecimalType(10, 2)))\n",
    "        .dropDuplicates([\"product_id\"])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9fb7ba0-04dc-4088-bd1b-5097b8b24951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SILVER STORE REGION \n",
    "@dlt.table(\n",
    "    name=\"silver_store_region\",\n",
    "    comment=\"Cleaned store and region reference data\",\n",
    "    table_properties={\"quality\": \"silver\"}\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_store_id\", \"store_id IS NOT NULL\")\n",
    "def silver_store_region():\n",
    "\n",
    "    df = dlt.read_stream(\"bronze_store_region\")\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"store_name\", F.trim(F.initcap(\"store_name\")))\n",
    "        .withColumn(\"region\", F.upper(\"region\"))\n",
    "        .withColumn(\"country\", F.upper(\"country\"))\n",
    "        .dropDuplicates([\"store_id\"])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}